{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeLWoP7ciBWr",
        "outputId": "bfcb983d-2892-42d0-9fa8-61d06792d010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.31.0-py3-none-any.whl (17.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.4 (from gradio)\n",
            "  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.13.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson (from gradio)\n",
            "  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=1221466a6656b08d8a1eb7350ba8ea5789dc5458d23d7526ddf0527a9eccee57\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, aiosignal, httpx, fastapi, aiohttp, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 fastapi-0.95.2 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.31.0 gradio-client-0.2.5 h11-0.14.0 httpcore-0.17.1 httpx-0.24.1 huggingface-hub-0.14.1 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 multidict-6.0.4 orjson-3.8.12 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhrftnLCpMYw",
        "outputId": "13d22622-0070-4633-b090-3c845af564ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.15.2+cu118)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.6.12 (from segmentation_models_pytorch)\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.65.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (8.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.1+cu118)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n",
            "  Downloading munch-3.0.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12->segmentation_models_pytorch) (6.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.6.12->segmentation_models_pytorch) (0.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (16.0.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.12->segmentation_models_pytorch) (2023.4.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.6.12->segmentation_models_pytorch) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=91d1f9017ffdf9bbd2d74f567ca210a7d3ac6b03a743ccfb0494b6a6005d61c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=729db3082c64b89ae7ec8388077302dcc37910a307ff2fe4d3c10a5b97868b02\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation_models_pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-3.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.3.2 timm-0.6.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "DEVICE = 'cpu'\n",
        "device = DEVICE\n",
        "EPOCHS = 10\n",
        "LR = 0.003\n",
        "IMAGE_HEIGHT = 320\n",
        "IMAGE_WIDTH = 320\n",
        "BATCH_SIZE = 8\n",
        "ENCODER = 'resnet50'\n",
        "WEIGHTS = 'imagenet'\n",
        "class DeepLabV3Model (nn.Module):\n",
        "    def __init__(self):\n",
        "        super (DeepLabV3Model , self).__init__()\n",
        "\n",
        "        self.arc = smp.DeepLabV3Plus(\n",
        "            encoder_name= ENCODER , # loading pre-trained model\n",
        "            encoder_weights=  WEIGHTS , # loading pre-trained weights\n",
        "            in_channels= 3 ,\n",
        "            classes=  4,\n",
        "            activation = 'softmax'\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, images, masks=None):\n",
        "        logits = self.arc(images)\n",
        "\n",
        "        if masks is not None:\n",
        "            masks = masks.squeeze(1) # remove the channel dimension\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            loss = criterion(logits, masks)\n",
        "            return logits, loss\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "L8G4eMRbo2tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import segmentation_models_pytorch as smp\n",
        "import numpy as np\n",
        "import cv2\n",
        "# Load the saved PyTorch model from the .pth file\n",
        "state_dict = torch.load('/content/drive/MyDrive/deployable_model.pth')\n",
        "model = DeepLabV3Model()\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "ZxXvxrEXlSdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a086c010-1004-4703-8741-776a78f96697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 136MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepLabV3Model(\n",
              "  (arc): DeepLabV3Plus(\n",
              "    (encoder): ResNetEncoder(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): DeepLabV3PlusDecoder(\n",
              "      (aspp): Sequential(\n",
              "        (0): ASPP(\n",
              "          (convs): ModuleList(\n",
              "            (0): Sequential(\n",
              "              (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "            (1): ASPPSeparableConv(\n",
              "              (0): SeparableConv2d(\n",
              "                (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False)\n",
              "                (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              )\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "            (2): ASPPSeparableConv(\n",
              "              (0): SeparableConv2d(\n",
              "                (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False)\n",
              "                (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              )\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "            (3): ASPPSeparableConv(\n",
              "              (0): SeparableConv2d(\n",
              "                (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=2048, bias=False)\n",
              "                (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              )\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU()\n",
              "            )\n",
              "            (4): ASPPPooling(\n",
              "              (0): AdaptiveAvgPool2d(output_size=1)\n",
              "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (3): ReLU()\n",
              "            )\n",
              "          )\n",
              "          (project): Sequential(\n",
              "            (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU()\n",
              "            (3): Dropout(p=0.5, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): SeparableConv2d(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (3): ReLU()\n",
              "      )\n",
              "      (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
              "      (block1): Sequential(\n",
              "        (0): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "      (block2): Sequential(\n",
              "        (0): SeparableConv2d(\n",
              "          (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
              "          (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (segmentation_head): SegmentationHead(\n",
              "      (0): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
              "      (2): Activation(\n",
              "        (activation): Softmax(dim=None)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_to_rgb(mask):\n",
        "    color_map={\n",
        "    0: (0, 0, 0),  # Background\n",
        "    1: (255,0,0),  # Class 1\n",
        "    2: (0,255,0),   # Class 2\n",
        "    3: (0,0,255),  # Class 3 # Class 5\n",
        "    }\n",
        "    if isinstance(mask, torch.Tensor):\n",
        "        mask = mask.detach().cpu().numpy()\n",
        "    # Create a new numpy array to hold the RGB mask\n",
        "    rgb_mask = np.zeros((320, 320, 3), dtype=np.uint8)\n",
        "\n",
        "    for row in range(320):\n",
        "        for column in range(320):\n",
        "            class_index = mask[0][row][column]\n",
        "            rgb_mask[row][column] = color_map[class_index]\n",
        "\n",
        "    return rgb_mask"
      ],
      "metadata": {
        "id": "R28WazsWv3DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as fn\n",
        "import torchvision\n",
        "def get_segmentation(image_path):\n",
        "  image = cv2.imread(image_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  image = np.transpose(image ,(2,0,1)).astype(np.float32)\n",
        "\n",
        "  original_image = torchvision.transforms.Resize((320, 320))(torch.Tensor(image))\n",
        "  image = original_image/255.0 # normalizing original image tensor [0,1] range\n",
        "  logits_mask = model(image.to(DEVICE).unsqueeze (0)) #(C, H, W) -> (1, C, H, W)\n",
        "  pred_mask_prob = torch.softmax(logits_mask, dim=1)  # (batch_size, num_classes, height, width)\n",
        "  _, pred_mask = torch.max(pred_mask_prob, dim=1)\n",
        "  plt.imshow(mask_to_rgb(pred_mask))\n",
        "image_path = '/content/drive/MyDrive/inputs/10.jpg'\n",
        "get_segmentation(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "UZh9fbYcthMU",
        "outputId": "f192a1ba-4992-4a2c-d2f3-e29cec811ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/segmentation_models_pytorch/base/modules.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self.activation(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio code"
      ],
      "metadata": {
        "id": "VuogimQZ4kF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define your function that performs image segmentation\n",
        "def perform_segmentation(image):\n",
        "    # image = cv2.imread(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image = np.transpose(image ,(2,0,1)).astype(np.float32)\n",
        "\n",
        "    original_image = torchvision.transforms.Resize((320, 320))(torch.Tensor(image))\n",
        "    image = original_image/255.0 # normalizing original image tensor [0,1] range\n",
        "    logits_mask = model(image.to(DEVICE).unsqueeze (0)) #(C, H, W) -> (1, C, H, W)\n",
        "    pred_mask_prob = torch.softmax(logits_mask, dim=1)  # (batch_size, num_classes, height, width)\n",
        "    _, pred_mask = torch.max(pred_mask_prob, dim=1)\n",
        "    plt.imshow(mask_to_rgb(pred_mask))\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    # Convert the Matplotlib plot to a NumPy array\n",
        "    fig = plt.gcf()\n",
        "    fig.canvas.draw()\n",
        "    output_image = np.array(fig.canvas.renderer._renderer)\n",
        "    plt.close()\n",
        "    # Return the segmented image as a NumPy array\n",
        "    output_image = Image.fromarray(output_image)\n",
        "\n",
        "# Return the segmented image as a PIL image object\n",
        "    return output_image\n",
        "\n",
        "# Define the Gradio interface\n",
        "input_image = gr.inputs.Image(label=\"Input Image\")\n",
        "output_image = gr.outputs.Image(type='pil',label=\"Segmented Image\")\n",
        "\n",
        "# Define the Gradio app\n",
        "app = gr.Interface(fn=perform_segmentation, inputs=input_image, outputs=output_image)\n",
        "\n",
        "# Launch the app\n",
        "app.launch()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "dmDA2l75y3EH",
        "outputId": "37e5c1ec-c8d0-4bae-d63e-7fdc63e3f875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:259: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:262: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:43: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HMga88kGeu9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}